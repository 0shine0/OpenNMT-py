

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Doc: Modules &mdash; OpenNMT-py  documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="OpenNMT-py  documentation" href="index.html"/>
        <link rel="next" title="Doc: Data Loaders" href="onmt.io.html"/>
        <link rel="prev" title="Doc: Framework" href="onmt.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> OpenNMT-py
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="main.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.html">Doc: Framework</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Doc: Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#core-modules">Core Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#encoders">Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#decoders">Decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#attention">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#architecture-transfomer">Architecture: Transfomer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#architecture-conv2conv">Architecture: Conv2Conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#architecture-sru">Architecture: SRU</a></li>
<li class="toctree-l2"><a class="reference internal" href="#alternative-encoders">Alternative Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#copy-attention">Copy Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#structured-attention">Structured Attention</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="onmt.io.html">Doc: Data Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/preprocess.html">Options: preprocess.py:</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/train.html">Options: train.py:</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/translate.html">Options: translate.py:</a></li>
<li class="toctree-l1"><a class="reference internal" href="extended.html">Example: Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Summarization.html">Example: Summarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="im2text.html">Example: Image to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech2text.html">Example: Speech to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTORS.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="ref.html">References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenNMT-py</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Doc: Modules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/onmt.modules.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="doc-modules">
<h1>Doc: Modules<a class="headerlink" href="#doc-modules" title="Permalink to this headline">¶</a></h1>
<div class="section" id="core-modules">
<h2>Core Modules<a class="headerlink" href="#core-modules" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.Embeddings">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">Embeddings</code><span class="sig-paren">(</span><em>word_vec_size</em>, <em>position_encoding</em>, <em>feat_merge</em>, <em>feat_vec_exponent</em>, <em>feat_vec_size</em>, <em>dropout</em>, <em>word_padding_idx</em>, <em>feat_padding_idx</em>, <em>word_vocab_size</em>, <em>feat_vocab_sizes=[]</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.Embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Words embeddings for encoder/decoder.</p>
<p>Additionally includes ability to add sparse input features
based on “Linguistic Input Features Improve Neural Machine Translation”
<a class="reference internal" href="ref.html#sennrich2016linguistic" id="id1">[SH16]</a>.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <script>mermaid.initialize({startOnLoad:true});</script><div class="mermaid">
            graph LR
   A[Input]
   C[Feature 1 Lookup]
   A--&gt;B[Word Lookup]
   A--&gt;C
   A--&gt;D[Feature N Lookup]
   B--&gt;E[MLP/Concat]
   C--&gt;E
   D--&gt;E
   E--&gt;F[Output]
        </div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word_vec_size</strong> (<em>int</em>) – size of the dictionary of embeddings.</li>
<li><strong>word_padding_idx</strong> (<em>int</em>) – padding index for words in the embeddings.</li>
<li><strong>feats_padding_idx</strong> (<em>list of int</em>) – padding index for a list of features
in the embeddings.</li>
<li><strong>word_vocab_size</strong> (<em>int</em>) – size of dictionary of embeddings for words.</li>
<li><strong>feat_vocab_sizes</strong> (<em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – list of size of dictionary
of embeddings for each feature.</li>
<li><strong>position_encoding</strong> (<em>bool</em>) – see <a class="reference internal" href="#onmt.modules.PositionalEncoding" title="onmt.modules.PositionalEncoding"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.PositionalEncoding</span></code></a></li>
<li><strong>feat_merge</strong> (<em>string</em>) – merge action for the features embeddings:
concat, sum or mlp.</li>
<li><strong>feat_vec_exponent</strong> (<em>float</em>) – when using <cite>-feat_merge concat</cite>, feature
embedding size is N^feat_dim_exponent, where N is the
number of values of feature takes.</li>
<li><strong>feat_vec_size</strong> (<em>int</em>) – embedding dimension for features when using
<cite>-feat_merge mlp</cite></li>
<li><strong>dropout</strong> (<em>float</em>) – dropout probability.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.Embeddings.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.Embeddings.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the embeddings for words and features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<cite>LongTensor</cite>) – index tensor <cite>[len x batch x nfeat]</cite></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">word embeddings <cite>[len x batch x embedding_size]</cite></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><cite>FloatTensor</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="onmt.modules.Embeddings.load_pretrained_vectors">
<code class="descname">load_pretrained_vectors</code><span class="sig-paren">(</span><em>emb_file</em>, <em>fixed</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.Embeddings.load_pretrained_vectors" title="Permalink to this definition">¶</a></dt>
<dd><p>Load in pretrained embeddings.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>emb_file</strong> (<em>str</em>) – path to torch serialized embeddings</li>
<li><strong>fixed</strong> (<em>bool</em>) – if true, embeddings are not updated</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="encoders">
<h2>Encoders<a class="headerlink" href="#encoders" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.EncoderBase">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">EncoderBase</code><a class="headerlink" href="#onmt.modules.EncoderBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Base encoder class. Specifies the interface used by different encoder types
and required by <a class="reference internal" href="onmt.html#onmt.Models.NMTModel" title="onmt.Models.NMTModel"><code class="xref py py-obj docutils literal"><span class="pre">onmt.Models.NMTModel</span></code></a>.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[Input]
   subgraph RNN
     C[Pos 1]
     D[Pos 2]
     E[Pos N]
   end
   F[Context]
   G[Final]
   A--&gt;C
   A--&gt;D
   A--&gt;E
   C--&gt;F
   D--&gt;F
   E--&gt;F
   E--&gt;G
        </div><dl class="method">
<dt id="onmt.modules.EncoderBase.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em>, <em>hidden=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.EncoderBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<code class="xref py py-obj docutils literal"><span class="pre">LongTensor</span></code>) – padded sequences of sparse indices <cite>[src_len x batch x nfeat]</cite></li>
<li><strong>lengths</strong> (<code class="xref py py-obj docutils literal"><span class="pre">LongTensor</span></code>) – length of each sequence <cite>[batch]</cite></li>
<li><strong>hidden</strong> (<em>class specific</em>) – initial hidden state.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Returns:k</dt>
<dd><dl class="first last docutils">
<dt>(tuple of <code class="xref py py-obj docutils literal"><span class="pre">FloatTensor</span></code>, <code class="xref py py-obj docutils literal"><span class="pre">FloatTensor</span></code>):</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>final encoder state, used to initialize decoder</dt>
<dd><cite>[layers x batch x hidden]</cite></dd>
</dl>
</li>
<li>contexts for attention, <cite>[src_len x batch x hidden]</cite></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.MeanEncoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">MeanEncoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.MeanEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>A trivial non-recurrent encoder. Simply applies mean pooling.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_layers</strong> (<em>int</em>) – number of replicated layers</li>
<li><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.Embeddings</span></code></a>) – embedding module to use</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.MeanEncoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em>, <em>hidden=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.MeanEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.EncoderBase.forward" title="onmt.modules.EncoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="decoders">
<h2>Decoders<a class="headerlink" href="#decoders" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.RNNDecoderBase">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">RNNDecoderBase</code><span class="sig-paren">(</span><em>rnn_type</em>, <em>bidirectional_encoder</em>, <em>num_layers</em>, <em>hidden_size</em>, <em>attn_type</em>, <em>coverage_attn</em>, <em>context_gate</em>, <em>copy_attn</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.RNNDecoderBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Base recurrent attention-based decoder class.
Specifies the interface used by different decoder types
and required by <a class="reference internal" href="onmt.html#onmt.Models.NMTModel" title="onmt.Models.NMTModel"><code class="xref py py-obj docutils literal"><span class="pre">onmt.Models.NMTModel</span></code></a>.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[Input]
   subgraph RNN
      C[Pos 1]
      D[Pos 2]
      E[Pos N]
   end
   G[Decoder State]
   H[Decoder State]
   I[Outputs]
   F[Context]
   A--emb--&gt;C
   A--emb--&gt;D
   A--emb--&gt;E
   H--&gt;C
   C-- attn --- F
   D-- attn --- F
   E-- attn --- F
   C--&gt;I
   D--&gt;I
   E--&gt;I
   E--&gt;G
   F---I
        </div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rnn_type</strong> (<code class="xref py py-obj docutils literal"><span class="pre">str</span></code>) – style of recurrent unit to use, one of [RNN, LSTM, GRU, SRU]</li>
<li><strong>bidirectional_encoder</strong> (<em>bool</em>) – use with a bidirectional encoder</li>
<li><strong>num_layers</strong> (<em>int</em>) – number of stacked layers</li>
<li><strong>hidden_size</strong> (<em>int</em>) – hidden size of each layer</li>
<li><strong>attn_type</strong> (<em>str</em>) – see <a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.GlobalAttention</span></code></a></li>
<li><strong>coverage_attn</strong> (<em>str</em>) – see <a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.GlobalAttention</span></code></a></li>
<li><strong>context_gate</strong> (<em>str</em>) – see <code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.ContextGate</span></code></li>
<li><strong>copy_attn</strong> (<em>bool</em>) – setup a separate copy attention mechanism</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout value for <code class="xref py py-obj docutils literal"><span class="pre">nn.Dropout</span></code></li>
<li><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.Embeddings</span></code></a>) – embedding module to use</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.RNNDecoderBase.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>context</em>, <em>state</em>, <em>context_lengths=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.RNNDecoderBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<cite>LongTensor</cite>) – sequences of padded tokens
<cite>[tgt_len x batch x nfeats]</cite>.</li>
<li><strong>context</strong> (<cite>FloatTensor</cite>) – vectors from the encoder
<cite>[src_len x batch x hidden]</cite>.</li>
<li><strong>state</strong> (<a class="reference internal" href="onmt.html#onmt.Models.DecoderState" title="onmt.Models.DecoderState"><code class="xref py py-obj docutils literal"><span class="pre">onmt.Models.DecoderState</span></code></a>) – decoder state object to initialize the decoder</li>
<li><strong>context_lengths</strong> (<cite>LongTensor</cite>) – the padded source lengths
<cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><ul class="simple">
<li><dl class="first docutils">
<dt>outputs: output from the decoder</dt>
<dd><cite>[tgt_len x batch x hidden]</cite>.</dd>
</dl>
</li>
<li>state: final hidden state from the decoder</li>
<li><dl class="first docutils">
<dt>attns: distribution over src at each tgt</dt>
<dd><cite>[tgt_len x batch x src_len]</cite>.</dd>
</dl>
</li>
</ul>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(<cite>FloatTensor</cite>,:obj:<cite>onmt.Models.DecoderState</cite>,`FloatTensor`)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.StdRNNDecoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">StdRNNDecoder</code><span class="sig-paren">(</span><em>rnn_type</em>, <em>bidirectional_encoder</em>, <em>num_layers</em>, <em>hidden_size</em>, <em>attn_type</em>, <em>coverage_attn</em>, <em>context_gate</em>, <em>copy_attn</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.StdRNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Standard fully batched RNN decoder with attention.
Faster implementation, uses CuDNN for implementation.
See <a class="reference internal" href="#onmt.modules.RNNDecoderBase" title="onmt.modules.RNNDecoderBase"><code class="xref py py-obj docutils literal"><span class="pre">RNNDecoderBase</span></code></a> for options.</p>
<p>Based around the approach from
“Neural Machine Translation By Jointly Learning To Align and Translate”
<a class="reference internal" href="ref.html#bahdanau2015" id="id2">[BCB14]</a></p>
<p>Implemented without input_feeding and currently with no <cite>coverage_attn</cite>
or <cite>copy_attn</cite> support.</p>
</dd></dl>

<dl class="class">
<dt id="onmt.modules.InputFeedRNNDecoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">InputFeedRNNDecoder</code><span class="sig-paren">(</span><em>rnn_type</em>, <em>bidirectional_encoder</em>, <em>num_layers</em>, <em>hidden_size</em>, <em>attn_type</em>, <em>coverage_attn</em>, <em>context_gate</em>, <em>copy_attn</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.InputFeedRNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Input feeding based decoder. See <a class="reference internal" href="#onmt.modules.RNNDecoderBase" title="onmt.modules.RNNDecoderBase"><code class="xref py py-obj docutils literal"><span class="pre">RNNDecoderBase</span></code></a> for options.</p>
<p>Based around the input feeding approach from
“Effective Approaches to Attention-based Neural Machine Translation”
<a class="reference internal" href="ref.html#luong2015" id="id3">[LPM15]</a></p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[Input n-1]
   AB[Input n]
   subgraph RNN
     E[Pos n-1]
     F[Pos n]
     E --&gt; F
   end
   G[Encoder]
   H[Context n-1]
   A --&gt; E
   AB --&gt; F
   E --&gt; H
   G --&gt; H
        </div></dd></dl>

</div>
<div class="section" id="attention">
<h2>Attention<a class="headerlink" href="#attention" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.GlobalAttention">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">GlobalAttention</code><span class="sig-paren">(</span><em>dim</em>, <em>coverage=False</em>, <em>attn_type='dot'</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.GlobalAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Global attention takes a matrix and a query vector. It
then computes a parameterized convex combination of the matrix
based on the input query.</p>
<p>Constructs a unit mapping a query <cite>q</cite> of size <cite>dim</cite>
and a source matrix <cite>H</cite> of size <cite>n x dim</cite>, to an output
of size <cite>dim</cite>.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[Query]
   subgraph RNN
     C[H 1]
     D[H 2]
     E[H N]
   end
   F[Attn]
   G[Output]
   A --&gt; F
   C --&gt; F
   D --&gt; F
   E --&gt; F
   C -.-&gt; G
   D -.-&gt; G
   E -.-&gt; G
   F --&gt; G
        </div><p>All models compute the output as
<span class="math">\(c = \sum_{j=1}^{SeqLength} a_j H_j\)</span> where
<span class="math">\(a_j\)</span> is the softmax of a score function.
Then then apply a projection layer to [q, c].</p>
<p>However they
differ on how they compute the attention score.</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>Luong Attention (dot, general):</dt>
<dd><ul class="first last">
<li>dot: <span class="math">\(score(H_j,q) = H_j^T q\)</span></li>
<li>general: <span class="math">\(score(H_j, q) = H_j^T W_a q\)</span></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Bahdanau Attention (mlp):</dt>
<dd><ul class="first last">
<li><span class="math">\(score(H_j, q) = v_a^T tanh(W_a q + U_a h_j)\)</span></li>
</ul>
</dd>
</dl>
</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dim</strong> (<em>int</em>) – dimensionality of query and key</li>
<li><strong>coverage</strong> (<em>bool</em>) – use coverage term</li>
<li><strong>attn_type</strong> (<em>str</em>) – type of attention to use, options [dot,general,mlp]</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.GlobalAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>context</em>, <em>context_lengths=None</em>, <em>coverage=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.GlobalAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<cite>FloatTensor</cite>) – query vectors <cite>[batch x tgt_len x dim]</cite></li>
<li><strong>context</strong> (<cite>FloatTensor</cite>) – source vectors <cite>[batch x src_len x dim]</cite></li>
<li><strong>context_lengths</strong> (<cite>LongTensor</cite>) – the source context lengths <cite>[batch]</cite></li>
<li><strong>coverage</strong> (<cite>FloatTensor</cite>) – None (not supported yet)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><ul class="simple">
<li>Computed vector <cite>[tgt_len x batch x dim]</cite></li>
<li><dl class="first docutils">
<dt>Attention distribtutions for each query</dt>
<dd><cite>[tgt_len x batch x src_len]</cite></dd>
</dl>
</li>
</ul>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(<cite>FloatTensor</cite>, <cite>FloatTensor</cite>)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="onmt.modules.GlobalAttention.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>h_t</em>, <em>h_s</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.GlobalAttention.score" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>h_t</strong> (<cite>FloatTensor</cite>) – sequence of queries <cite>[batch x tgt_len x dim]</cite></li>
<li><strong>h_s</strong> (<cite>FloatTensor</cite>) – sequence of sources <cite>[batch x src_len x dim]</cite></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">raw attention scores (unnormalized) for each src index
<cite>[batch x tgt_len x src_len]</cite></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><code class="xref py py-obj docutils literal"><span class="pre">FloatTensor</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="architecture-transfomer">
<h2>Architecture: Transfomer<a class="headerlink" href="#architecture-transfomer" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.PositionalEncoding">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">PositionalEncoding</code><span class="sig-paren">(</span><em>dropout</em>, <em>dim</em>, <em>max_len=5000</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.PositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the sinusoidal positional encoding for
non-recurrent neural networks.</p>
<p>Implementation based on “Attention Is All You Need”
[DBLP:journals/corr/VaswaniSPUJGKP17]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dropout</strong> (<em>float</em>) – dropout parameter</li>
<li><strong>dim</strong> (<em>int</em>) – embedding size</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="onmt.modules.PositionwiseFeedForward">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">PositionwiseFeedForward</code><span class="sig-paren">(</span><em>size</em>, <em>hidden_size</em>, <em>dropout=0.1</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.PositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>A two-layer Feed-Forward-Network with residual layer norm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>size</strong> (<em>int</em>) – the size of input for the first-layer of the FFN.</li>
<li><strong>hidden_size</strong> (<em>int</em>) – the hidden layer size of the second-layer
of the FNN.</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout probability(0-1.0).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="onmt.modules.TransformerEncoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">TransformerEncoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>hidden_size</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.TransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>The Transformer encoder from “Attention is All You Need”.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[input]
   B[multi-head self-attn]
   C[feed forward]
   O[output]
   A --&gt; B
   B --&gt; C
   C --&gt; O
        </div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_layers</strong> (<em>int</em>) – number of encoder layers</li>
<li><strong>hidden_size</strong> (<em>int</em>) – number of hidden units</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout parameters</li>
<li><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.Embeddings</span></code></a>) – embeddings to use, should have positional encodings</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.TransformerEncoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em>, <em>hidden=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.TransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.EncoderBase.forward" title="onmt.modules.EncoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.TransformerDecoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">TransformerDecoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>hidden_size</em>, <em>attn_type</em>, <em>copy_attn</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.TransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>The Transformer decoder from “Attention is All You Need”.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[input]
   B[multi-head self-attn]
   BB[multi-head src-attn]
   C[feed forward]
   O[output]
   A --&gt; B
   B --&gt; BB
   BB --&gt; C
   C --&gt; O
        </div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_layers</strong> (<em>int</em>) – number of encoder layers.</li>
<li><strong>hidden_size</strong> (<em>int</em>) – number of hidden units</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout parameters</li>
<li><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.Embeddings</span></code></a>) – embeddings to use, should have positional encodings</li>
<li><strong>attn_type</strong> (<em>str</em>) – if using a seperate copy attention</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.TransformerDecoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>context</em>, <em>state</em>, <em>context_lengths=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.TransformerDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.RNNDecoderBase.forward" title="onmt.modules.RNNDecoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.RNNDecoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.MultiHeadedAttention">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">MultiHeadedAttention</code><span class="sig-paren">(</span><em>head_count</em>, <em>model_dim</em>, <em>dropout=0.1</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.MultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-Head Attention module from
“Attention is All You Need”
[DBLP:journals/corr/VaswaniSPUJGKP17].</p>
<p>Similar to standard <cite>dot</cite> attention but uses
multiple attention distributions simulataneously
to select relevant items.</p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[key]
   B[value]
   C[query]
   O[output]
   subgraph Attn
     D[Attn 1]
     E[Attn 2]
     F[Attn N]
   end
   A --&gt; D
   C --&gt; D
   A --&gt; E
   C --&gt; E
   A --&gt; F
   C --&gt; F
   D --&gt; O
   E --&gt; O
   F --&gt; O
   B --&gt; O
        </div><p>Also includes several additional tricks.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>head_count</strong> (<em>int</em>) – number of parallel heads</li>
<li><strong>model_dim</strong> (<em>int</em>) – the dimension of keys/values/queries,
must be divisible by head_count</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout parameter</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.MultiHeadedAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>key</em>, <em>value</em>, <em>query</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.MultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the context vector and the attention vectors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>key</strong> (<cite>FloatTensor</cite>) – set of <cite>key_len</cite>
key vectors <cite>[batch, key_len, dim]</cite></li>
<li><strong>value</strong> (<cite>FloatTensor</cite>) – set of <cite>key_len</cite>
value vectors <cite>[batch, key_len, dim]</cite></li>
<li><strong>query</strong> (<cite>FloatTensor</cite>) – set of <cite>query_len</cite>
query vectors  <cite>[batch, query_len, dim]</cite></li>
<li><strong>mask</strong> – binary mask indicating which keys have
non-zero attention <cite>[batch, query_len, key_len]</cite></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><ul class="simple">
<li>output context vectors <cite>[batch, query_len, dim]</cite></li>
<li>one of the attention vectors <cite>[batch, query_len, key_len]</cite></li>
</ul>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(<cite>FloatTensor</cite>, <cite>FloatTensor</cite>)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="architecture-conv2conv">
<h2>Architecture: Conv2Conv<a class="headerlink" href="#architecture-conv2conv" title="Permalink to this headline">¶</a></h2>
<p>(These methods are from a user contribution
and have not been thoroughly tested.)</p>
<dl class="class">
<dt id="onmt.modules.CNNEncoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">CNNEncoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>hidden_size</em>, <em>cnn_kernel_width</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder built on CNN based on
[DBLP:journals/corr/GehringAGYD17].</p>
<dl class="method">
<dt id="onmt.modules.CNNEncoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em>, <em>hidden=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.EncoderBase.forward" title="onmt.modules.EncoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.EncoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.CNNDecoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">CNNDecoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>hidden_size</em>, <em>attn_type</em>, <em>copy_attn</em>, <em>cnn_kernel_width</em>, <em>dropout</em>, <em>embeddings</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Decoder built on CNN, based on [DBLP:journals/corr/GehringAGYD17].</p>
<p>Consists of residual convolutional layers, with ConvMultiStepAttention.</p>
<dl class="method">
<dt id="onmt.modules.CNNDecoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>context</em>, <em>state</em>, <em>context_lengths=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.RNNDecoderBase.forward" title="onmt.modules.RNNDecoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.RNNDecoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="onmt.modules.ConvMultiStepAttention">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">ConvMultiStepAttention</code><span class="sig-paren">(</span><em>input_size</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.ConvMultiStepAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Conv attention takes a key matrix, a value matrix and a query vector.
Attention weight is calculated by key matrix with the query vector
and sum on the value matrix. And the same operation is applied
in each decode conv layer.</p>
<dl class="method">
<dt id="onmt.modules.ConvMultiStepAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>base_target_emb</em>, <em>input</em>, <em>encoder_out_top</em>, <em>encoder_out_combine</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.ConvMultiStepAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>base_target_emb</strong> – target emb tensor</li>
<li><strong>input</strong> – output of decode conv</li>
<li><strong>encoder_out_t</strong> – the key matrix for calculation of attetion weight,
which is the top output of encode conv</li>
<li><strong>encoder_out_combine</strong> – the value matrix for the attention-weighted sum,
which is the combination of base emb and top output of encode</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="onmt.modules.WeightNorm">
<code class="descclassname">onmt.modules.</code><code class="descname">WeightNorm</code><a class="headerlink" href="#onmt.modules.WeightNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#onmt.modules.WeightNorm" title="onmt.modules.WeightNorm"><code class="xref py py-class docutils literal"><span class="pre">onmt.modules.WeightNorm</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="architecture-sru">
<h2>Architecture: SRU<a class="headerlink" href="#architecture-sru" title="Permalink to this headline">¶</a></h2>
<dl class="attribute">
<dt id="onmt.modules.SRU">
<code class="descclassname">onmt.modules.</code><code class="descname">SRU</code><a class="headerlink" href="#onmt.modules.SRU" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#onmt.modules.SRU" title="onmt.modules.SRU"><code class="xref py py-class docutils literal"><span class="pre">onmt.modules.SRU</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="alternative-encoders">
<h2>Alternative Encoders<a class="headerlink" href="#alternative-encoders" title="Permalink to this headline">¶</a></h2>
<p>onmt.modules.AudioEncoder</p>
<dl class="class">
<dt id="onmt.modules.AudioEncoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">AudioEncoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>bidirectional</em>, <em>rnn_size</em>, <em>dropout</em>, <em>sample_rate</em>, <em>window_size</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.AudioEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple encoder convolutional -&gt; recurrent neural network for
audio input.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_layers</strong> (<em>int</em>) – number of encoder layers.</li>
<li><strong>bidirectional</strong> (<em>bool</em>) – bidirectional encoder.</li>
<li><strong>rnn_size</strong> (<em>int</em>) – size of hidden states of the rnn.</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout probablity.</li>
<li><strong>sample_rate</strong> (<em>float</em>) – input spec</li>
<li><strong>window_size</strong> (<em>int</em>) – input spec</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.AudioEncoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.AudioEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.EncoderBase.forward" title="onmt.modules.EncoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.EncoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

<p>onmt.modules.ImageEncoder</p>
<dl class="class">
<dt id="onmt.modules.ImageEncoder">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">ImageEncoder</code><span class="sig-paren">(</span><em>num_layers</em>, <em>bidirectional</em>, <em>rnn_size</em>, <em>dropout</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.ImageEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple encoder convolutional -&gt; recurrent neural network for
image input.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_layers</strong> (<em>int</em>) – number of encoder layers.</li>
<li><strong>bidirectional</strong> (<em>bool</em>) – bidirectional encoder.</li>
<li><strong>rnn_size</strong> (<em>int</em>) – size of hidden states of the rnn.</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout probablity.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.ImageEncoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>input</em>, <em>lengths=None</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.ImageEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.modules.EncoderBase.forward" title="onmt.modules.EncoderBase.forward"><code class="xref py py-obj docutils literal"><span class="pre">onmt.modules.EncoderBase.forward()</span></code></a></p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="copy-attention">
<h2>Copy Attention<a class="headerlink" href="#copy-attention" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.CopyGenerator">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">CopyGenerator</code><span class="sig-paren">(</span><em>input_size</em>, <em>tgt_dict</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CopyGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator module that additionally considers copying
words directly from the source.</p>
<p>The main idea is that we have an extended “dynamic dictionary”.
It contains <cite>|tgt_dict|</cite> words plus an arbitrary number of
additional words introduced by the source sentence.
For each source sentence we have a <cite>src_map</cite> that maps
each source word to an index in <cite>tgt_dict</cite> if it known, or
else to an extra word.</p>
<p>The copy generator is an extended version of the standard
generator that computse three values.</p>
<ul class="simple">
<li><span class="math">\(p_{softmax}\)</span> the standard softmax over <cite>tgt_dict</cite></li>
<li><span class="math">\(p(z)\)</span> the probability of instead copying a
word from the source, computed using a bernoulli</li>
<li><span class="math">\(p_{copy}\)</span> the probility of copying a word instead.
taken from the attention distribution directly.</li>
</ul>
<p>The model returns a distribution over the extend dictionary,
computed as</p>
<p><span class="math">\(p(w) = p(z=1)  p_{copy}(w)  +  p(z=0)  p_{softmax}(w)\)</span></p>

            <style>
            /* mermaid issue 527 workaround */
            .section {
                opacity: 1.0 !important;
            }
            </style>
            <div class="mermaid">
            graph BT
   A[input]
   S[src_map]
   B[softmax]
   BB[switch]
   C[attn]
   D[copy]
   O[output]
   A --&gt; B
   A --&gt; BB
   S --&gt; D
   C --&gt; D
   D --&gt; O
   B --&gt; O
   BB --&gt; O
        </div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input_size</strong> (<em>int</em>) – size of input representation</li>
<li><strong>tgt_dict</strong> (<em>Vocab</em>) – output target dictionary</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="onmt.modules.CopyGenerator.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>hidden</em>, <em>attn</em>, <em>src_map</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.CopyGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a distribution over the target dictionary
extended by the dynamic dictionary implied by compying
source words.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden</strong> (<cite>FloatTensor</cite>) – hidden outputs <cite>[batch*tlen, input_size]</cite></li>
<li><strong>attn</strong> (<cite>FloatTensor</cite>) – attn for each <cite>[batch*tlen, input_size]</cite></li>
<li><strong>src_map</strong> (<cite>FloatTensor</cite>) – A sparse indicator matrix mapping each source word to
its index in the “extended” vocab containing.
<cite>[src_len, batch, extra_words]</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="structured-attention">
<h2>Structured Attention<a class="headerlink" href="#structured-attention" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="onmt.modules.MatrixTree">
<em class="property">class </em><code class="descclassname">onmt.modules.</code><code class="descname">MatrixTree</code><span class="sig-paren">(</span><em>eps=1e-05</em><span class="sig-paren">)</span><a class="headerlink" href="#onmt.modules.MatrixTree" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the matrix-tree theorem for computing marginals
of non-projective dependency parsing. This attention layer is used
in the paper “Learning Structured Text Representations.”</p>
<p><a class="reference internal" href="ref.html#dblp-journals-corr-liul17d" id="id8">[LL17]</a></p>
</dd></dl>

</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="onmt.io.html" class="btn btn-neutral float-right" title="Doc: Data Loaders" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="onmt.html" class="btn btn-neutral" title="Doc: Framework" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, srush.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" src="https://unpkg.com/mermaid@7.1.0/dist/mermaid.min.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>